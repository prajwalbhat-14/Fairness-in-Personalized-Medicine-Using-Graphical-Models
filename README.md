# Fairness-in-Personalized-Medicine-Using-Graphical-Models
This Bayesian Networks project focused on fairness and predictive modeling for personalized medicine using graphical models well-suited to capture complex dependencies in healthcare data. Fairness is an important issue within the scope of personalized treatments where biases may be based on demographic factors such as age, gender, or ethnicity and therefore lead to biased model predictions and to the continuation of health disparities. The primary objective is to develop a prediction model for treatment outcomes based on patientâ€™s characteristics, such that these predictions are unbiased and fair. A set of fairness metrics of interest is utilized to analyze the model's performance on different sensitive groups through reweighting or post-processing techniques to reduce the biases observed. The adjustment of the model is more believable and robust because it focuses on the concept of fairness, thus making it more ethical and reliable for use in healthcare applications. Exploiting the interpretability of Bayesian Networks, the project found a dependency between treatment outcomes and demographic attributes, which gives insight into how certain factors affect predictions. Bias mitigation methods significantly improved the reduced disparities in treatment recommendations, reducing disparities much more closely to fairness standards, while underpinning the future of ethical AI in healthcare. The paper contributed to this field by combining fairness evaluation tools with interpretable models, paving the way for much more equitable systems of personalized treatment in practice.
